{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FYP_Final_File.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c666f0440ecf40899a40f28d7d67cf84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bc844bc0b87f426787822541ee147615",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4053f08c09d74779929b9f66979cfc41",
              "IPY_MODEL_0e55477db7164aa58df9a01253fb2ddf"
            ]
          }
        },
        "bc844bc0b87f426787822541ee147615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4053f08c09d74779929b9f66979cfc41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a559e21a58cc49f6956135f70d717f3b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 133546016,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 133546016,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c631a680cdc47ec85d2d34479bfc463"
          }
        },
        "0e55477db7164aa58df9a01253fb2ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e5323db04024469b2ff6b80102fb9fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 127M/127M [00:13&lt;00:00, 10.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a05da6fde83744d4bb37b040d9b51072"
          }
        },
        "a559e21a58cc49f6956135f70d717f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c631a680cdc47ec85d2d34479bfc463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e5323db04024469b2ff6b80102fb9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a05da6fde83744d4bb37b040d9b51072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA1oFP-8FfCC"
      },
      "source": [
        "#Libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from google.colab import drive\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch import nn, optim\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzmTShRud8uF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e10214-6fc8-4a4f-b5b0-7267783e72d0"
      },
      "source": [
        "#To Mount Google Drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "os.chdir(\"/content/gdrive/MyDrive/FYP\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiUN_y8F0DOj"
      },
      "source": [
        "#converting Videos into their Frames and saving them under a Folder of their Label#\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import torchvision\n",
        "\n",
        "def readVideo():\n",
        "\n",
        "    glossList = []\n",
        "    vidList = []\n",
        "    bblst = []\n",
        "    path = os.getcwd()\n",
        "    content = json.load(open('WLASL_v0.3.json'))\n",
        "    for ent in content:\n",
        "        gloss = ent['gloss']\n",
        "        instances = ent['instances']\n",
        "        for inst in instances:\n",
        "            split = inst['split']\n",
        "            if split == \"train\":\n",
        "                video = inst['video_id'] + \".mp4\"\n",
        "                x = inst['bbox']\n",
        "                \n",
        "                x1 = x[1]\n",
        "                x2 = x[3]\n",
        "                y1 = x[0]\n",
        "                y2 = x[2]\n",
        "                if os.path.isfile(str(video)):\n",
        "                    \n",
        "                    glossList.append(str(gloss))\n",
        "                    vidList.append(str(video))\n",
        "                    bblst.append([x1,x2,y1,y2])\n",
        "    \n",
        "    print(\"---------------------------\")\n",
        "    oldPath = os.getcwd()\n",
        "    path = os.path.join(str(path),\"Frames\")\n",
        "    print(path)\n",
        "\n",
        "    i = 0            \n",
        "    for j in vidList: #use this to get the video number\n",
        "        newPath = os.path.join(path, str(glossList[i]))\n",
        "        print(newPath)\n",
        "        if not os.path.exists(newPath):\n",
        "            os.mkdir(newPath)    \n",
        "    \n",
        "        vidcap = cv2.VideoCapture(j)\n",
        "        os.chdir(newPath)\n",
        "        print(os.getcwd())\n",
        "        newPath2 = os.path.join(newPath, (j))\n",
        "        #print(newPath2)\n",
        "        if not os.path.exists(newPath2):\n",
        "            os.mkdir(newPath2)\n",
        "            os.chdir(newPath2)\n",
        "        print(os.getcwd())\n",
        "        #getting bbox of the vid\n",
        "        t = bblst[i]\n",
        "        x1 = t[0]\n",
        "        x2 = t[1]\n",
        "        y1 = t[2]\n",
        "        y2 = t[3]\n",
        "        success,image = vidcap.read()\n",
        "        print(os.getcwd())\n",
        "        count = 0\n",
        "       \n",
        "        while success:\n",
        "            image = image[x1:x2,y1:y2]\n",
        "            cv2.imwrite(\"frame%d.jpg\" % count, image)\n",
        "            success,image = vidcap.read()\n",
        "            count += 1\n",
        "        os.chdir(oldPath)\n",
        "        print(os.getcwd())\n",
        "        i+=1\n",
        "\n",
        "        print(\"-----------------------------------------------\")\n",
        "readVideo()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rwam79TYW1VM",
        "outputId": "c753d109-b63d-4967-c594-63eb0e5367e5"
      },
      "source": [
        "import os\n",
        "import csv\n",
        "###PATH.PY FOR CSV FILE\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "os.chdir(\"/content/gdrive/MyDrive/FYP\")\n",
        "print(os.listdir(os.getcwd()))\n",
        "def image():\n",
        "    imglbl = []\n",
        "    imgPath = []\n",
        "    tempPath = []\n",
        "    imgFrm = []\n",
        "    \n",
        "    path = os.getcwd()\n",
        "    print(path)\n",
        "    newPath = \"trainData/Samples\"\n",
        "    newPath = os.path.join(path, newPath)\n",
        "    os.chdir(newPath)\n",
        "\n",
        "    dirLen = len(os.listdir())\n",
        "    imglbl.append(os.listdir())    \n",
        "    os.chdir(path)\n",
        "\n",
        "    with open('myCSV.csv', 'w', newline = '') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Image_Label\", \"Image_Frames\", \"Image_Path\"])\n",
        "        for i in range(dirLen):\n",
        "            x = imglbl[0][i]\n",
        "            customPath = os.path.join(newPath, str(x))\n",
        "            os.chdir(customPath)\n",
        "            y = (os.listdir())\n",
        "            for j in range(len(y)):\n",
        "                imgPath.append(customPath + '/' + y[j])\n",
        "                tempPath.append(imgPath[-1])\n",
        "                os.chdir(tempPath[-1])\n",
        "                imgFrm.append(len(os.listdir())-1)                \n",
        "                writer.writerow([str(imglbl[0][i]), imgFrm[-1], imgPath[-1]])\n",
        "image()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "['trainData', 'myCSV.csv', 'myCSV.gsheet']\n",
            "/content/gdrive/MyDrive/FYP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GBusb-maLEg",
        "outputId": "f5bffa29-3ee0-4b0e-9527-d0d44609b335"
      },
      "source": [
        "#DATA LOADER MD 4\n",
        "#Change Directory\n",
        "os.chdir(\"/content/gdrive/MyDrive/FYP\")\n",
        "print(os.getcwd())\n",
        "\n",
        "#Read CSV File\n",
        "df = pd.read_csv('myCSV1.csv')\n",
        "#Get CSV File Length\n",
        "dfLen = len(df.index)+1\n",
        "\n",
        "#Arrays Declarations\n",
        "tensorList = []\n",
        "labelList = []\n",
        "label = \"\"\n",
        "\n",
        "#Get Img Labels\n",
        "imglblList = []\n",
        "for column in df[['Image_Label']]:\n",
        "    imglbl = df[column]\n",
        "for i in imglbl.values:\n",
        "    imglblList.append(i)\n",
        "\n",
        "#Get Img Frames    \n",
        "imgFramesList = []\n",
        "for column in df[['Image_Frames']]:\n",
        "    imgFrames = df[column]\n",
        "for i in imgFrames.values:\n",
        "    imgFramesList.append(i)\n",
        "    \n",
        "#Get Img Path\n",
        "imgPathList = []\n",
        "for column in df[['Image_Path']]:\n",
        "    imgPath = df[column]\n",
        "for i in imgPath.values:\n",
        "    imgPathList.append(i)\n",
        "\n",
        "X = df.Image_Path.values\n",
        "y = df.Image_Label.values\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/FYP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH3SI_q1IcrE",
        "outputId": "c19b621a-add5-41ef-82c7-f7f1223d1cc6"
      },
      "source": [
        "#########################################333 TO LOAD IMAGES FROM THEIR PATH ##################################################\n",
        "trans = transforms.Compose([ transforms.ToTensor(),\n",
        "                                                 transforms.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989])])\n",
        "\n",
        "#Open, Resize and Transform Images\n",
        "def loader(imglbl, imgPath, imgFrames):\n",
        "        tensorArr=[]\n",
        "        imgDir = os.chdir(imgPath)\n",
        "        print(imglbl)\n",
        "        print(imgPath)\n",
        "        print(imgFrames)\n",
        "        print(\"=------------------------------------------------------------------------------------------=\")\n",
        "        for x in range(imgFrames):\n",
        "            image = Image.open('frame'+str(x)+'.jpg')\n",
        "            new_image = image.resize((32, 32))\n",
        "            new_image2 = trans(new_image)\n",
        "            tensorArr.append(new_image2)\n",
        "        \n",
        "        label = imglbl    \n",
        "        return tensorArr, new_image2, label\n",
        "\n",
        "#Image output and labels from loader will be stacked into a tensor\n",
        "print(imglblList)\n",
        "\n",
        "for i in range(dfLen-1):\n",
        "    #Function call to loader\n",
        "    tensorArr,x , label = loader(imglblList[i], imgPathList[i], imgFramesList[i])\n",
        "\n",
        "    stackTensor = torch.stack(tensorArr)\n",
        "    \n",
        "    #Numpy Array of the TensorList\n",
        "    tensorList.append(stackTensor)\n",
        "    \n",
        "    #Numpy Array of the LabelList\n",
        "    labelList.append(label)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'a', 'a', 'a', 'abdomen', 'abdomen', 'abdomen', 'abdomen', 'a lot', 'a lot', 'a lot', 'a lot', 'able', 'able', 'able', 'able', 'about', 'about', 'about', 'about', 'about', 'about', 'about', 'above', 'above', 'above', 'above', 'accept', 'accept', 'accept', 'accept', 'accept', 'accept', 'accent', 'accent', 'accent', 'accent', 'accident', 'accident', 'accident', 'accident', 'accident', 'accident', 'accident', 'accident', 'accident', 'accident', 'accident', 'accident', 'accident', 'across', 'across', 'across', 'across', 'across', 'across', 'across', 'act', 'act', 'act', 'act', 'act', 'accomplish', 'accomplish', 'accomplish', 'accomplish', 'accomplish', 'accomplish', 'accountant', 'accountant', 'accountant', 'accountant', 'accountant', 'action', 'action', 'action', 'action', 'active', 'active', 'active', 'active', 'active', 'activity', 'activity', 'activity', 'activity', 'activity', 'actor', 'actor', 'actor', 'actor', 'actor', 'actor', 'actor', 'adapt', 'adapt', 'adapt', 'adapt', 'adapt', 'address', 'address', 'address', 'address', 'address', 'add', 'add', 'add', 'add', 'add', 'add', 'add', 'adjective', 'adjective', 'adjective', 'adjective', 'adjective', 'adjust', 'adjust', 'adjust', 'adjust', 'adjust', 'admire', 'admire', 'admire', 'admire', 'admire', 'admit', 'admit', 'admit', 'admit', 'admit', 'adult', 'adult', 'adult', 'adult', 'adult', 'adult', 'adult', 'adult', 'adopt', 'adopt', 'adopt', 'adopt', 'adopt', 'advanced', 'advanced', 'advanced', 'advanced', 'advanced', 'advantage', 'advantage', 'advantage', 'advantage', 'advantage', 'advantage', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'with', 'will', 'will', 'will', 'will', 'will', 'will', 'will', 'will', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'wow', 'wow', 'wow', 'wow', 'wow', 'wow', 'wow', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'your', 'your', 'your', 'your', 'your', 'your', 'your', 'your', 'your', 'your', 'zero', 'zero', 'zero', 'zero', 'zero', 'zero', 'adverb', 'adverb', 'adverb', 'adverb', 'adverb', 'bath', 'bath', 'bath', 'bath', 'bath', 'bath', 'bath', 'bath', 'bath', 'bath', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'book', 'bike', 'bike', 'bike', 'bathroom', 'bathroom', 'bathroom', 'bathroom', 'bathroom', 'bathroom', 'bathroom', 'bathroom', 'bathroom', 'bathroom', 'bathroom', 'break', 'break', 'break', 'break', 'break', 'break', 'break', 'bull', 'bull', 'bull', 'bull', 'bull', 'bull', 'caption', 'caption', 'caption', 'caption', 'caption', 'caption', 'caption', 'chair', 'chair', 'chair', 'chair', 'chair', 'chair', 'chair', 'chair', 'chair', 'chair', 'chair', 'chair', 'chair', 'chair', 'chair', 'chair', 'chair', 'chair', 'choice', 'choice', 'choice', 'choice', 'choice', 'choice', 'choice', 'coat', 'coat', 'coat', 'coat', 'coat', 'coat', 'cow', 'cow', 'cow', 'cow', 'cow', 'cow', 'cow', 'cow', 'cow', 'cow', 'cow', 'cow', 'cow', 'dark', 'dark', 'dark', 'dark', 'dark', 'dark', 'dark', 'dark', 'dark', 'dark', 'dark', 'dark', 'dark', 'diarrhea', 'diarrhea', 'diarrhea', 'diarrhea', 'diarrhea', 'diarrhea', 'drag', 'drag', 'drag', 'drag', 'drag', 'delay', 'delay', 'delay', 'delay', 'delay', 'delay', 'delay', 'delay', 'delay', 'delay', 'eat', 'eat', 'eat', 'eat', 'eat', 'eat', 'eat', 'eat', 'eat', 'eat', 'eat', 'enter', 'enter', 'enter', 'enter', 'enter', 'enter', 'enter', 'enter', 'elevator', 'elevator', 'elevator', 'elevator', 'elevator', 'elevator', 'elevator', 'far', 'far', 'far', 'far', 'far', 'far', 'far', 'far', 'far', 'far', 'fat', 'fat', 'fat', 'fat', 'fat', 'fat', 'fat', 'fat', 'fat', 'fat', 'fire', 'fire', 'fire', 'fire', 'fire', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'fork', 'fork', 'fork', 'fork', 'fork', 'fork', 'garage', 'garage', 'garage', 'garage', 'garage', 'garage', 'garage', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glasses', 'glasses', 'glasses', 'glasses', 'glasses', 'glasses', 'glasses', 'glasses', 'glasses', 'guess', 'guess', 'guess', 'guess', 'guess', 'guess', 'guess', 'guess', 'hear', 'hear', 'hear', 'hear', 'hear', 'hear', 'hear', 'hear', 'hear', 'hear', 'hide', 'hide', 'hide', 'hide', 'hide', 'heart', 'heart', 'heart', 'heart', 'heart', 'heart', 'heart', 'heart', 'heart', 'heart', 'home', 'home', 'home', 'home', 'home', 'home', 'home', 'home', 'home', 'home', 'how', 'how', 'how', 'how', 'how', 'how', 'how', 'how', 'how', 'how', 'how', 'i', 'i', 'i', 'i', 'i', 'if', 'if', 'if', 'if', 'if', 'if', 'if', 'ill', 'ill', 'ill', 'ill', 'ill', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'j', 'j', 'j', 'j', 'j', 'jail', 'jail', 'jail', 'jail', 'jail', 'k', 'k', 'k', 'k', 'k', 'kick', 'kick', 'kick', 'kick', 'kick', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'language', 'language', 'language', 'language', 'language', 'language', 'language', 'language', 'language', 'language', 'language', 'language', 'lady', 'lady', 'lady', 'lady', 'lady', 'late', 'late', 'late', 'late', 'late', 'late', 'late', 'late', 'late', 'late', 'late', 'later', 'later', 'later', 'later', 'later', 'later', 'later', 'later', 'later', 'later', 'later', 'later', 'later', 'later', 'law', 'law', 'law', 'law', 'law', 'law', 'law', 'law', 'law', 'law', 'lip', 'lip', 'lip', 'lip', 'lip', 'lie', 'lie', 'lie', 'lie', 'lie', 'lie', 'lie', 'lie', 'lesbian', 'lesbian', 'lesbian', 'lesbian', 'lesbian', 'lesbian', 'look at', 'look at', 'look at', 'look at', 'look at', 'mad', 'mad', 'mad', 'mad', 'mad', 'mad', 'mad', 'm', 'm', 'm', 'm', 'm', 'look for', 'look for', 'look for', 'look for', 'look for', 'man', 'man', 'man', 'man', 'man', 'man', 'man', 'man', 'man', 'man', 'man', 'man', 'man', 'man', 'me', 'me', 'me', 'me', 'me', 'me', 'mom', 'mom', 'mom', 'mom', 'mom', 'mom', 'milk', 'milk', 'milk', 'milk', 'milk', 'milk', 'milk', 'milk', 'milk', 'monday', 'monday', 'monday', 'monday', 'monday', 'monday', 'monday', 'money', 'money', 'money', 'money', 'money', 'money', 'money', 'money', 'money', 'more', 'more', 'more', 'more', 'more', 'more', 'more', 'more', 'more', 'more', 'name', 'name', 'name', 'name', 'name', 'name', 'name', 'name', 'name', 'name', 'must', 'must', 'must', 'must', 'must', 'must', 'must', 'n', 'n', 'n', 'n', 'n', 'napkin', 'napkin', 'napkin', 'napkin', 'napkin', 'napkin', 'napkin', 'neck', 'neck', 'neck', 'neck', 'neck', 'neck', 'neck', 'niece', 'niece', 'niece', 'niece', 'niece', 'niece', 'niece', 'niece', 'niece', 'nephew', 'nephew', 'nephew', 'nephew', 'nephew', 'nephew', 'nephew', 'nephew', 'nephew', 'o', 'o', 'o', 'o', 'o', 'odd', 'odd', 'odd', 'odd', 'odd', 'odd', 'off', 'off', 'off', 'off', 'off', 'off', 'off', 'off', 'off', 'old', 'old', 'old', 'old', 'old', 'old', 'old', 'old', 'old', 'old', 'on', 'on', 'on', 'on', 'on', 'on', 'or', 'or', 'or', 'or', 'or', 'pain', 'pain', 'pain', 'pain', 'pain', 'pain', 'pain', 'part', 'part', 'part', 'part', 'part', 'pay', 'pay', 'pay', 'pay', 'pay', 'pay', 'pay', 'pay', 'pay', 'pet', 'pet', 'pet', 'pet', 'pet', 'pick', 'pick', 'pick', 'pick', 'pick', 'quick', 'quick', 'quick', 'quick', 'quick', 'quick', 'quick', 'pity', 'pity', 'pity', 'pity', 'pity', 'rage', 'rage', 'rage', 'rage', 'rage', 'rent', 'rent', 'rent', 'rent', 'rent', 'rat', 'rat', 'rat', 'rat', 'rat', 'rat', 'rat', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'salary', 'salary', 'salary', 'salary', 'salary', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'ruin', 'ruin', 'ruin', 'ruin', 'ruin', 'save', 'save', 'save', 'save', 'save', 'save', 'save', 'save', 'save', 'saw', 'saw', 'saw', 'saw', 'saw', 'sea', 'sea', 'sea', 'sea', 'sea', 'say', 'say', 'say', 'say', 'say', 'say', 'say', 'sell', 'sell', 'sell', 'sell', 'sell', 'sell', 'sell', 'see', 'see', 'see', 'see', 'see', 'see', 'she', 'she', 'she', 'she', 'she', 'she', 'sin', 'sin', 'sin', 'sin', 'sin', 'some', 'some', 'some', 'some', 'some', 'some', 'some', 'some', 'some', 'some', 'sorry', 'sorry', 'sorry', 'sorry', 'sorry', 'sorry', 'sorry', 'sorry', 'sorry', 'sorry', 'son', 'son', 'son', 'son', 'son', 'son', 'son', 'son', 'son', 'son', 'son', 'son', 'son', 'sun', 'sun', 'sun', 'sun', 'sun', 'sun', 'sun', 'take', 'take', 'take', 'take', 'take', 'take', 'take', 'take', 'take', 'take', 'talk', 'talk', 'talk', 'talk', 'talk', 'talk', 'talk', 'talk', 'talk', 'tea', 'tea', 'tea', 'tea', 'tea', 'tea', 'tea', 'tea', 'tea', 'tea', 'tea', 'tea', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'text', 'text', 'text', 'text', 'text', 'than', 'than', 'than', 'than', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'that', 'their', 'their', 'their', 'their', 'their', 'their', 'them', 'them', 'them', 'them', 'them', 'time', 'time', 'time', 'time', 'time', 'time', 'time', 'time', 'time', 'time', 'time', 'time', 'time', 'this', 'this', 'this', 'this', 'this', 'then', 'then', 'then', 'then', 'then', 'then', 'they', 'they', 'they', 'they', 'they', 'they', 'to', 'to', 'to', 'to', 'to', 'to', 'under', 'under', 'under', 'under', 'under', 'under', 'try', 'try', 'try', 'try', 'try', 'try', 'try', 'until', 'until', 'until', 'until', 'until', 'until', 'until', 'until', 'up', 'up', 'up', 'up', 'up', 'up', 'up', 'use', 'use', 'use', 'use', 'use', 'use', 'use', 'use', 'use', 'verb', 'verb', 'verb', 'verb', 'verb', 'verb', 'very', 'very', 'very', 'very', 'very', 'vote', 'vote', 'vote', 'vote', 'vote', 'vote', 'vote', 'vote', 'vote', 'vote', 'walk', 'walk', 'walk', 'walk', 'walk', 'walk', 'walk', 'walk', 'walk', 'walk', 'walk', 'walk', 'walk', 'walk', 'walk', 'wait', 'wait', 'wait', 'wait', 'wait', 'wait', 'wait', 'wait', 'wait', 'wait', 'wait', 'wait', 'wait', 'wallet', 'wallet', 'wallet', 'wallet', 'wallet', 'watch', 'watch', 'watch', 'watch', 'watch', 'watch', 'watch', 'watch', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'where', 'where', 'where', 'where', 'where', 'where', 'where', 'where', 'where', 'which', 'which', 'which', 'which', 'which', 'which', 'which', 'which', 'which', 'while', 'while', 'while', 'while', 'while', 'while', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'why', 'why']\n",
            "a\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/a/01611.mp4\n",
            "48\n",
            "=------------------------------------------------------------------------------------------=\n",
            "a\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/a/01614.mp4\n",
            "65\n",
            "=------------------------------------------------------------------------------------------=\n",
            "a\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/a/01615.mp4\n",
            "84\n",
            "=------------------------------------------------------------------------------------------=\n",
            "a\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/a/01610.mp4\n",
            "124\n",
            "=------------------------------------------------------------------------------------------=\n",
            "abdomen\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/abdomen/00336.mp4\n",
            "64\n",
            "=------------------------------------------------------------------------------------------=\n",
            "abdomen\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/abdomen/00337.mp4\n",
            "27\n",
            "=------------------------------------------------------------------------------------------=\n",
            "abdomen\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/abdomen/00340.mp4\n",
            "61\n",
            "=------------------------------------------------------------------------------------------=\n",
            "abdomen\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/abdomen/00341.mp4\n",
            "83\n",
            "=------------------------------------------------------------------------------------------=\n",
            "a lot\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/a lot/02124.mp4\n",
            "73\n",
            "=------------------------------------------------------------------------------------------=\n",
            "a lot\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/a lot/02125.mp4\n",
            "37\n",
            "=------------------------------------------------------------------------------------------=\n",
            "a lot\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/a lot/02131.mp4\n",
            "85\n",
            "=------------------------------------------------------------------------------------------=\n",
            "a lot\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/a lot/02129.mp4\n",
            "28\n",
            "=------------------------------------------------------------------------------------------=\n",
            "able\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/able/00377.mp4\n",
            "88\n",
            "=------------------------------------------------------------------------------------------=\n",
            "able\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/able/00378.mp4\n",
            "40\n",
            "=------------------------------------------------------------------------------------------=\n",
            "able\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/able/00383.mp4\n",
            "75\n",
            "=------------------------------------------------------------------------------------------=\n",
            "able\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/able/00384.mp4\n",
            "84\n",
            "=------------------------------------------------------------------------------------------=\n",
            "about\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/about/00415.mp4\n",
            "37\n",
            "=------------------------------------------------------------------------------------------=\n",
            "about\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/about/00414.mp4\n",
            "104\n",
            "=------------------------------------------------------------------------------------------=\n",
            "about\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/about/00419.mp4\n",
            "63\n",
            "=------------------------------------------------------------------------------------------=\n",
            "about\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/about/00422.mp4\n",
            "65\n",
            "=------------------------------------------------------------------------------------------=\n",
            "about\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/about/00423.mp4\n",
            "72\n",
            "=------------------------------------------------------------------------------------------=\n",
            "about\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/about/00425.mp4\n",
            "61\n",
            "=------------------------------------------------------------------------------------------=\n",
            "about\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/about/65002.mp4\n",
            "71\n",
            "=------------------------------------------------------------------------------------------=\n",
            "above\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/above/65004.mp4\n",
            "63\n",
            "=------------------------------------------------------------------------------------------=\n",
            "above\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/above/00433.mp4\n",
            "78\n",
            "=------------------------------------------------------------------------------------------=\n",
            "above\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/above/00435.mp4\n",
            "102\n",
            "=------------------------------------------------------------------------------------------=\n",
            "above\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/above/00430.mp4\n",
            "51\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accept\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accept/00593.mp4\n",
            "27\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accept\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accept/00588.mp4\n",
            "29\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accept\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accept/00597.mp4\n",
            "127\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accept\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accept/00598.mp4\n",
            "63\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accept\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accept/00599.mp4\n",
            "38\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accept\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accept/00603.mp4\n",
            "84\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accent\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accent/00583.mp4\n",
            "37\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accent\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accent/00584.mp4\n",
            "41\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accent\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accent/00587.mp4\n",
            "29\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accent\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accent/00586.mp4\n",
            "38\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accident\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accident/00618.mp4\n",
            "26\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accident\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accident/00630.mp4\n",
            "62\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accident\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accident/00629.mp4\n",
            "148\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accident\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accident/00628.mp4\n",
            "34\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accident\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accident/00624.mp4\n",
            "108\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accident\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accident/00623.mp4\n",
            "103\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accident\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accident/00631.mp4\n",
            "74\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accident\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accident/00632.mp4\n",
            "54\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accident\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accident/00633.mp4\n",
            "24\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accident\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accident/00639.mp4\n",
            "104\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accident\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accident/65009.mp4\n",
            "55\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accident\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accident/00636.mp4\n",
            "81\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accident\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accident/00638.mp4\n",
            "58\n",
            "=------------------------------------------------------------------------------------------=\n",
            "across\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/across/00841.mp4\n",
            "67\n",
            "=------------------------------------------------------------------------------------------=\n",
            "across\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/across/00842.mp4\n",
            "88\n",
            "=------------------------------------------------------------------------------------------=\n",
            "across\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/across/00839.mp4\n",
            "50\n",
            "=------------------------------------------------------------------------------------------=\n",
            "across\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/across/00840.mp4\n",
            "80\n",
            "=------------------------------------------------------------------------------------------=\n",
            "across\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/across/00836.mp4\n",
            "41\n",
            "=------------------------------------------------------------------------------------------=\n",
            "across\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/across/00835.mp4\n",
            "43\n",
            "=------------------------------------------------------------------------------------------=\n",
            "across\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/across/00829.mp4\n",
            "52\n",
            "=------------------------------------------------------------------------------------------=\n",
            "act\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/act/00847.mp4\n",
            "113\n",
            "=------------------------------------------------------------------------------------------=\n",
            "act\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/act/00849.mp4\n",
            "86\n",
            "=------------------------------------------------------------------------------------------=\n",
            "act\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/act/00850.mp4\n",
            "82\n",
            "=------------------------------------------------------------------------------------------=\n",
            "act\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/act/00851.mp4\n",
            "77\n",
            "=------------------------------------------------------------------------------------------=\n",
            "act\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/act/67346.mp4\n",
            "43\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accomplish\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accomplish/00663.mp4\n",
            "116\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accomplish\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accomplish/00662.mp4\n",
            "52\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accomplish\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accomplish/00668.mp4\n",
            "78\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accomplish\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accomplish/00666.mp4\n",
            "35\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accomplish\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accomplish/65010.mp4\n",
            "71\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accomplish\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accomplish/67343.mp4\n",
            "59\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accountant\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accountant/00691.mp4\n",
            "57\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accountant\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accountant/00693.mp4\n",
            "79\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accountant\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accountant/00690.mp4\n",
            "133\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accountant\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accountant/00694.mp4\n",
            "104\n",
            "=------------------------------------------------------------------------------------------=\n",
            "accountant\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/accountant/67344.mp4\n",
            "47\n",
            "=------------------------------------------------------------------------------------------=\n",
            "action\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/action/00855.mp4\n",
            "64\n",
            "=------------------------------------------------------------------------------------------=\n",
            "action\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/action/00854.mp4\n",
            "107\n",
            "=------------------------------------------------------------------------------------------=\n",
            "action\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/action/00858.mp4\n",
            "99\n",
            "=------------------------------------------------------------------------------------------=\n",
            "action\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/action/67345.mp4\n",
            "54\n",
            "=------------------------------------------------------------------------------------------=\n",
            "active\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/active/00869.mp4\n",
            "120\n",
            "=------------------------------------------------------------------------------------------=\n",
            "active\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/active/00870.mp4\n",
            "61\n",
            "=------------------------------------------------------------------------------------------=\n",
            "active\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/active/00871.mp4\n",
            "55\n",
            "=------------------------------------------------------------------------------------------=\n",
            "active\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/active/00873.mp4\n",
            "85\n",
            "=------------------------------------------------------------------------------------------=\n",
            "active\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/active/00874.mp4\n",
            "92\n",
            "=------------------------------------------------------------------------------------------=\n",
            "activity\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/activity/00890.mp4\n",
            "31\n",
            "=------------------------------------------------------------------------------------------=\n",
            "activity\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/activity/00891.mp4\n",
            "107\n",
            "=------------------------------------------------------------------------------------------=\n",
            "activity\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/activity/65016.mp4\n",
            "56\n",
            "=------------------------------------------------------------------------------------------=\n",
            "activity\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/activity/00893.mp4\n",
            "62\n",
            "=------------------------------------------------------------------------------------------=\n",
            "activity\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/activity/00894.mp4\n",
            "64\n",
            "=------------------------------------------------------------------------------------------=\n",
            "actor\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/actor/00897.mp4\n",
            "62\n",
            "=------------------------------------------------------------------------------------------=\n",
            "actor\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/actor/00899.mp4\n",
            "89\n",
            "=------------------------------------------------------------------------------------------=\n",
            "actor\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/actor/00902.mp4\n",
            "76\n",
            "=------------------------------------------------------------------------------------------=\n",
            "actor\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/actor/00901.mp4\n",
            "64\n",
            "=------------------------------------------------------------------------------------------=\n",
            "actor\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/actor/00904.mp4\n",
            "112\n",
            "=------------------------------------------------------------------------------------------=\n",
            "actor\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/actor/65017.mp4\n",
            "74\n",
            "=------------------------------------------------------------------------------------------=\n",
            "actor\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/actor/67347.mp4\n",
            "47\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adapt\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adapt/00946.mp4\n",
            "28\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adapt\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adapt/00947.mp4\n",
            "80\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adapt\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adapt/00949.mp4\n",
            "50\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adapt\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adapt/00950.mp4\n",
            "79\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adapt\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adapt/00951.mp4\n",
            "92\n",
            "=------------------------------------------------------------------------------------------=\n",
            "address\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/address/01012.mp4\n",
            "34\n",
            "=------------------------------------------------------------------------------------------=\n",
            "address\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/address/01018.mp4\n",
            "41\n",
            "=------------------------------------------------------------------------------------------=\n",
            "address\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/address/01020.mp4\n",
            "71\n",
            "=------------------------------------------------------------------------------------------=\n",
            "address\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/address/01024.mp4\n",
            "90\n",
            "=------------------------------------------------------------------------------------------=\n",
            "address\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/address/67348.mp4\n",
            "62\n",
            "=------------------------------------------------------------------------------------------=\n",
            "add\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/add/00967.mp4\n",
            "26\n",
            "=------------------------------------------------------------------------------------------=\n",
            "add\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/add/00962.mp4\n",
            "42\n",
            "=------------------------------------------------------------------------------------------=\n",
            "add\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/add/00963.mp4\n",
            "36\n",
            "=------------------------------------------------------------------------------------------=\n",
            "add\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/add/00964.mp4\n",
            "46\n",
            "=------------------------------------------------------------------------------------------=\n",
            "add\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/add/00965.mp4\n",
            "123\n",
            "=------------------------------------------------------------------------------------------=\n",
            "add\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/add/00972.mp4\n",
            "83\n",
            "=------------------------------------------------------------------------------------------=\n",
            "add\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/add/65018.mp4\n",
            "72\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adjective\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adjective/01065.mp4\n",
            "33\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adjective\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adjective/01066.mp4\n",
            "180\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adjective\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adjective/01067.mp4\n",
            "61\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adjective\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adjective/01068.mp4\n",
            "48\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adjective\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adjective/01069.mp4\n",
            "84\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adjust\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adjust/01075.mp4\n",
            "35\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adjust\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adjust/01078.mp4\n",
            "67\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adjust\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adjust/01076.mp4\n",
            "50\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adjust\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adjust/01077.mp4\n",
            "63\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adjust\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adjust/01079.mp4\n",
            "102\n",
            "=------------------------------------------------------------------------------------------=\n",
            "admire\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/admire/01101.mp4\n",
            "139\n",
            "=------------------------------------------------------------------------------------------=\n",
            "admire\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/admire/01102.mp4\n",
            "34\n",
            "=------------------------------------------------------------------------------------------=\n",
            "admire\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/admire/01107.mp4\n",
            "100\n",
            "=------------------------------------------------------------------------------------------=\n",
            "admire\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/admire/01106.mp4\n",
            "89\n",
            "=------------------------------------------------------------------------------------------=\n",
            "admire\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/admire/01103.mp4\n",
            "46\n",
            "=------------------------------------------------------------------------------------------=\n",
            "admit\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/admit/01118.mp4\n",
            "33\n",
            "=------------------------------------------------------------------------------------------=\n",
            "admit\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/admit/01120.mp4\n",
            "138\n",
            "=------------------------------------------------------------------------------------------=\n",
            "admit\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/admit/01121.mp4\n",
            "67\n",
            "=------------------------------------------------------------------------------------------=\n",
            "admit\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/admit/01122.mp4\n",
            "37\n",
            "=------------------------------------------------------------------------------------------=\n",
            "admit\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/admit/01127.mp4\n",
            "89\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adult\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adult/01206.mp4\n",
            "86\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adult\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adult/01207.mp4\n",
            "84\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adult\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adult/01209.mp4\n",
            "38\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adult\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adult/01212.mp4\n",
            "35\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adult\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adult/01214.mp4\n",
            "40\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adult\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adult/01216.mp4\n",
            "74\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adult\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adult/01217.mp4\n",
            "100\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adult\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adult/01208.mp4\n",
            "102\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adopt\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adopt/01157.mp4\n",
            "106\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adopt\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adopt/01149.mp4\n",
            "42\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adopt\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adopt/01160.mp4\n",
            "35\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adopt\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adopt/01162.mp4\n",
            "90\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adopt\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adopt/65022.mp4\n",
            "57\n",
            "=------------------------------------------------------------------------------------------=\n",
            "advanced\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/advanced/01227.mp4\n",
            "56\n",
            "=------------------------------------------------------------------------------------------=\n",
            "advanced\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/advanced/01228.mp4\n",
            "37\n",
            "=------------------------------------------------------------------------------------------=\n",
            "advanced\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/advanced/01231.mp4\n",
            "95\n",
            "=------------------------------------------------------------------------------------------=\n",
            "advanced\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/advanced/01230.mp4\n",
            "59\n",
            "=------------------------------------------------------------------------------------------=\n",
            "advanced\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/advanced/01229.mp4\n",
            "67\n",
            "=------------------------------------------------------------------------------------------=\n",
            "advantage\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/advantage/01242.mp4\n",
            "56\n",
            "=------------------------------------------------------------------------------------------=\n",
            "advantage\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/advantage/01247.mp4\n",
            "55\n",
            "=------------------------------------------------------------------------------------------=\n",
            "advantage\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/advantage/01249.mp4\n",
            "62\n",
            "=------------------------------------------------------------------------------------------=\n",
            "advantage\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/advantage/01251.mp4\n",
            "67\n",
            "=------------------------------------------------------------------------------------------=\n",
            "advantage\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/advantage/01252.mp4\n",
            "92\n",
            "=------------------------------------------------------------------------------------------=\n",
            "advantage\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/advantage/65025.mp4\n",
            "43\n",
            "=------------------------------------------------------------------------------------------=\n",
            "with\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/with/63587.mp4\n",
            "120\n",
            "=------------------------------------------------------------------------------------------=\n",
            "with\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/with/63588.mp4\n",
            "80\n",
            "=------------------------------------------------------------------------------------------=\n",
            "with\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/with/63589.mp4\n",
            "54\n",
            "=------------------------------------------------------------------------------------------=\n",
            "with\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/with/63590.mp4\n",
            "77\n",
            "=------------------------------------------------------------------------------------------=\n",
            "with\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/with/63591.mp4\n",
            "61\n",
            "=------------------------------------------------------------------------------------------=\n",
            "with\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/with/63592.mp4\n",
            "51\n",
            "=------------------------------------------------------------------------------------------=\n",
            "with\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/with/63593.mp4\n",
            "81\n",
            "=------------------------------------------------------------------------------------------=\n",
            "with\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/with/63595.mp4\n",
            "57\n",
            "=------------------------------------------------------------------------------------------=\n",
            "with\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/with/63596.mp4\n",
            "89\n",
            "=------------------------------------------------------------------------------------------=\n",
            "with\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/with/66795.mp4\n",
            "52\n",
            "=------------------------------------------------------------------------------------------=\n",
            "will\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/will/63358.mp4\n",
            "52\n",
            "=------------------------------------------------------------------------------------------=\n",
            "will\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/will/63360.mp4\n",
            "81\n",
            "=------------------------------------------------------------------------------------------=\n",
            "will\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/will/63363.mp4\n",
            "61\n",
            "=------------------------------------------------------------------------------------------=\n",
            "will\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/will/63364.mp4\n",
            "23\n",
            "=------------------------------------------------------------------------------------------=\n",
            "will\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/will/63370.mp4\n",
            "63\n",
            "=------------------------------------------------------------------------------------------=\n",
            "will\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/will/69536.mp4\n",
            "85\n",
            "=------------------------------------------------------------------------------------------=\n",
            "will\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/will/63369.mp4\n",
            "81\n",
            "=------------------------------------------------------------------------------------------=\n",
            "will\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/will/70350.mp4\n",
            "108\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/63666.mp4\n",
            "69\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/63667.mp4\n",
            "25\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/63665.mp4\n",
            "71\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/63668.mp4\n",
            "31\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/63672.mp4\n",
            "28\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/63671.mp4\n",
            "61\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/63670.mp4\n",
            "61\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/63673.mp4\n",
            "41\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/63676.mp4\n",
            "55\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/63677.mp4\n",
            "76\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/63678.mp4\n",
            "53\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/63679.mp4\n",
            "68\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/66798.mp4\n",
            "48\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/67078.mp4\n",
            "48\n",
            "=------------------------------------------------------------------------------------------=\n",
            "woman\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/woman/66799.mp4\n",
            "54\n",
            "=------------------------------------------------------------------------------------------=\n",
            "wow\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/wow/63947.mp4\n",
            "46\n",
            "=------------------------------------------------------------------------------------------=\n",
            "wow\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/wow/63948.mp4\n",
            "90\n",
            "=------------------------------------------------------------------------------------------=\n",
            "wow\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/wow/63949.mp4\n",
            "56\n",
            "=------------------------------------------------------------------------------------------=\n",
            "wow\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/wow/63951.mp4\n",
            "46\n",
            "=------------------------------------------------------------------------------------------=\n",
            "wow\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/wow/63953.mp4\n",
            "39\n",
            "=------------------------------------------------------------------------------------------=\n",
            "wow\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/wow/63955.mp4\n",
            "34\n",
            "=------------------------------------------------------------------------------------------=\n",
            "wow\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/wow/63964.mp4\n",
            "60\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/64280.mp4\n",
            "62\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/64281.mp4\n",
            "70\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/64283.mp4\n",
            "21\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/64284.mp4\n",
            "55\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/64288.mp4\n",
            "53\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/64289.mp4\n",
            "63\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/64290.mp4\n",
            "63\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/64291.mp4\n",
            "54\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/64294.mp4\n",
            "59\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/64292.mp4\n",
            "46\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/64295.mp4\n",
            "59\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/64296.mp4\n",
            "119\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/64300.mp4\n",
            "89\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/66820.mp4\n",
            "46\n",
            "=------------------------------------------------------------------------------------------=\n",
            "yes\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/yes/64299.mp4\n",
            "57\n",
            "=------------------------------------------------------------------------------------------=\n",
            "you\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/you/64382.mp4\n",
            "60\n",
            "=------------------------------------------------------------------------------------------=\n",
            "you\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/you/64383.mp4\n",
            "79\n",
            "=------------------------------------------------------------------------------------------=\n",
            "you\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/you/64381.mp4\n",
            "62\n",
            "=------------------------------------------------------------------------------------------=\n",
            "you\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/you/64384.mp4\n",
            "56\n",
            "=------------------------------------------------------------------------------------------=\n",
            "you\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/you/64388.mp4\n",
            "68\n",
            "=------------------------------------------------------------------------------------------=\n",
            "you\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/you/64386.mp4\n",
            "85\n",
            "=------------------------------------------------------------------------------------------=\n",
            "you\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/you/64385.mp4\n",
            "50\n",
            "=------------------------------------------------------------------------------------------=\n",
            "you\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/you/64389.mp4\n",
            "88\n",
            "=------------------------------------------------------------------------------------------=\n",
            "you\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/you/64390.mp4\n",
            "50\n",
            "=------------------------------------------------------------------------------------------=\n",
            "you\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/you/64391.mp4\n",
            "80\n",
            "=------------------------------------------------------------------------------------------=\n",
            "you\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/you/67015.mp4\n",
            "51\n",
            "=------------------------------------------------------------------------------------------=\n",
            "your\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/your/64427.mp4\n",
            "99\n",
            "=------------------------------------------------------------------------------------------=\n",
            "your\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/your/64429.mp4\n",
            "37\n",
            "=------------------------------------------------------------------------------------------=\n",
            "your\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/your/64430.mp4\n",
            "85\n",
            "=------------------------------------------------------------------------------------------=\n",
            "your\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/your/64431.mp4\n",
            "17\n",
            "=------------------------------------------------------------------------------------------=\n",
            "your\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/your/64432.mp4\n",
            "20\n",
            "=------------------------------------------------------------------------------------------=\n",
            "your\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/your/64433.mp4\n",
            "30\n",
            "=------------------------------------------------------------------------------------------=\n",
            "your\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/your/64435.mp4\n",
            "55\n",
            "=------------------------------------------------------------------------------------------=\n",
            "your\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/your/64436.mp4\n",
            "104\n",
            "=------------------------------------------------------------------------------------------=\n",
            "your\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/your/64437.mp4\n",
            "62\n",
            "=------------------------------------------------------------------------------------------=\n",
            "your\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/your/64438.mp4\n",
            "71\n",
            "=------------------------------------------------------------------------------------------=\n",
            "zero\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/zero/64546.mp4\n",
            "28\n",
            "=------------------------------------------------------------------------------------------=\n",
            "zero\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/zero/64547.mp4\n",
            "27\n",
            "=------------------------------------------------------------------------------------------=\n",
            "zero\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/zero/64544.mp4\n",
            "50\n",
            "=------------------------------------------------------------------------------------------=\n",
            "zero\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/zero/64548.mp4\n",
            "76\n",
            "=------------------------------------------------------------------------------------------=\n",
            "zero\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/zero/66825.mp4\n",
            "56\n",
            "=------------------------------------------------------------------------------------------=\n",
            "zero\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/zero/68193.mp4\n",
            "82\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adverb\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adverb/01265.mp4\n",
            "96\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adverb\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adverb/01266.mp4\n",
            "151\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adverb\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adverb/01267.mp4\n",
            "60\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adverb\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adverb/01269.mp4\n",
            "82\n",
            "=------------------------------------------------------------------------------------------=\n",
            "adverb\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/adverb/01268.mp4\n",
            "41\n",
            "=------------------------------------------------------------------------------------------=\n",
            "bath\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/bath/05270.mp4\n",
            "56\n",
            "=------------------------------------------------------------------------------------------=\n",
            "bath\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/bath/05275.mp4\n",
            "77\n",
            "=------------------------------------------------------------------------------------------=\n",
            "bath\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/bath/05279.mp4\n",
            "61\n",
            "=------------------------------------------------------------------------------------------=\n",
            "bath\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/bath/05280.mp4\n",
            "44\n",
            "=------------------------------------------------------------------------------------------=\n",
            "bath\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/bath/05281.mp4\n",
            "148\n",
            "=------------------------------------------------------------------------------------------=\n",
            "bath\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/bath/05282.mp4\n",
            "73\n",
            "=------------------------------------------------------------------------------------------=\n",
            "bath\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/bath/05284.mp4\n",
            "76\n",
            "=------------------------------------------------------------------------------------------=\n",
            "bath\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/bath/05285.mp4\n",
            "80\n",
            "=------------------------------------------------------------------------------------------=\n",
            "bath\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/bath/65147.mp4\n",
            "53\n",
            "=------------------------------------------------------------------------------------------=\n",
            "bath\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/bath/67393.mp4\n",
            "49\n",
            "=------------------------------------------------------------------------------------------=\n",
            "book\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/book/07068.mp4\n",
            "67\n",
            "=------------------------------------------------------------------------------------------=\n",
            "book\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/book/07070.mp4\n",
            "85\n",
            "=------------------------------------------------------------------------------------------=\n",
            "book\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/book/07069.mp4\n",
            "29\n",
            "=------------------------------------------------------------------------------------------=\n",
            "book\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/book/07071.mp4\n",
            "19\n",
            "=------------------------------------------------------------------------------------------=\n",
            "book\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/book/07073.mp4\n",
            "31\n",
            "=------------------------------------------------------------------------------------------=\n",
            "book\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/book/07075.mp4\n",
            "80\n",
            "=------------------------------------------------------------------------------------------=\n",
            "book\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/book/07076.mp4\n",
            "105\n",
            "=------------------------------------------------------------------------------------------=\n",
            "book\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/book/07074.mp4\n",
            "37\n",
            "=------------------------------------------------------------------------------------------=\n",
            "book\n",
            "/content/gdrive/MyDrive/FYP/trainData/Samples/book/07077.mp4\n",
            "116\n",
            "=------------------------------------------------------------------------------------------=\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ9ysMnVhlWr"
      },
      "source": [
        "import numpy as np\n",
        "os.chdir(\"/content/gdrive/MyDrive/FYP\")\n",
        "tensorList = np.load('tensorslast.npy',allow_pickle=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUz7wR7RFQOx",
        "outputId": "2ea4a746-7d69-42f3-c9c4-309d5e3e27d4"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "labels = np.load('labelslast.npy',allow_pickle=True)\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(labels)\n",
        "labels = le.transform(labels)\n",
        "\n",
        "print(labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0   0 ... 100 100 100]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQeLEZ98k4Ms",
        "outputId": "d7abf105-a575-4760-e2c1-4ff1347884b0"
      },
      "source": [
        "os.chdir(\"/content/gdrive/MyDrive/FYP\")\n",
        "label_Words = np.load('labels_word.npy',allow_pickle=True)\n",
        "print(label_Words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['accident' 'africa' 'all' 'apple' 'basketball' 'bed' 'before' 'bird'\n",
            " 'black' 'blue' 'book' 'bowling' 'brown' 'can' 'candy' 'cat' 'chair'\n",
            " 'change' 'cheat' 'city' 'clothes' 'color' 'computer' 'cook' 'cool' 'corn'\n",
            " 'cousin' 'cow' 'cry' 'dance' 'dark' 'deaf' 'decide' 'doctor' 'dog' 'door'\n",
            " 'drink' 'enjoy' 'family' 'fine' 'finish' 'fish' 'forget' 'full' 'give'\n",
            " 'go' 'graduate' 'hair' 'hat' 'hearing' 'help' 'hot' 'jacket' 'kiss'\n",
            " 'knife' 'language' 'last' 'later' 'learn' 'letter' 'like' 'man' 'many'\n",
            " 'medicine' 'meet' 'mother' 'no' 'now' 'orange' 'paint' 'paper' 'pink'\n",
            " 'pizza' 'play' 'pull' 'purple' 'read' 'secretary' 'shirt' 'short' 'son'\n",
            " 'study' 'table' 'tall' 'tell' 'thanksgiving' 'thin' 'thursday' 'time'\n",
            " 'visit' 'wait' 'walk' 'want' 'what' 'white' 'who' 'woman' 'work' 'wrong'\n",
            " 'year' 'yes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poqx5Jk7HN4T"
      },
      "source": [
        "#os.chdir(\"/content/gdrive/MyDrive/FYP/trainData/Samples\")\n",
        "import torch.nn.utils.rnn as rnn\n",
        "#Custom Dataloader\n",
        "class signData(Dataset):\n",
        "    def __init__(self, X, Y, transform = None):\n",
        "        #X is TensorList as argument\n",
        "        self.X = X\n",
        "        #Y is LabelList as argument\n",
        "        self.Y = Y\n",
        "        \n",
        "        if transform == 1:\n",
        "            self.transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                                 transforms.Resize((128,128))\n",
        "                                                 ,transforms.Normalize(mean=np.array([0.485, 0.456, 0.406]), std=np.array([0.229, 0.224, 0.225]))])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        #Accessing every instance of NpTensorArr\n",
        "        imageStack = self.X[index]\n",
        "        #Accesing every instance of NpLabelList\n",
        "        label = self.Y[index]\n",
        "        return torch.from_numpy(imageStack), len(imageStack), label \n",
        "\n",
        "\n",
        "#Use my_collate for Image Batching and normalizing image sizes\n",
        "def my_collate(batch):\n",
        "    inputs = rnn.pad_sequence([s[0] for s in batch], padding_value=0.0)\n",
        "    input_sizes = torch.LongTensor([s[1] for s in batch])\n",
        "    target = torch.LongTensor([s[2] for s in batch])\n",
        "    return inputs, input_sizes, target    \n",
        "\n",
        "\n",
        "\n",
        "#Transform Images\n",
        "trans = transforms.Compose([transforms.ToTensor(),transforms.Resize((128,128)),\n",
        "                                                 transforms.Normalize(mean=np.array([0.485, 0.456, 0.406]), std=np.array([0.229, 0.224, 0.225]))])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcnJg_fdDDnz"
      },
      "source": [
        "\n",
        "Data = signData(tensorList, labels, transform=1)\n",
        "\n",
        "train,val = torch.utils.data.random_split(Data, [1300, 297], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "train_arg = dict(batch_size=4, shuffle=True, collate_fn = my_collate) \n",
        "\n",
        "train_loader = DataLoader(train, **train_arg)\n",
        "\n",
        "val_loader = DataLoader(val, **train_arg)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c666f0440ecf40899a40f28d7d67cf84",
            "bc844bc0b87f426787822541ee147615",
            "4053f08c09d74779929b9f66979cfc41",
            "0e55477db7164aa58df9a01253fb2ddf",
            "a559e21a58cc49f6956135f70d717f3b",
            "0c631a680cdc47ec85d2d34479bfc463",
            "8e5323db04024469b2ff6b80102fb9fc",
            "a05da6fde83744d4bb37b040d9b51072"
          ]
        },
        "id": "sM9IIzImDDPa",
        "outputId": "35d295fc-9200-46db-8b0f-25fb06efbd8d"
      },
      "source": [
        "#Model Intializing\n",
        "model = torchvision.models.video.r3d_18(pretrained=True)\n",
        "\n",
        "\n",
        "#Parameter for Model Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr=0.0001\n",
        "weight_decay=0.0001\n",
        "factor=0.316\n",
        "\n",
        "#To transfer Model and Training from cpu to available gpu\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "import gc \n",
        "model.to(device)\n",
        "criterion.to(device)\n",
        "\n",
        "# Your code with pytorch using GPU \n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=lr, weight_decay=weight_decay)\n",
        "torch.cuda.memory_summary(device=device, abbreviated=False)\n",
        "\n",
        "\n",
        "def train(n_epochs, model, optimizer, criterion):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0  \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "\n",
        "        model.train()\n",
        "        for batch_idx, (data, dsize, target) in enumerate(train_loader):\n",
        "          device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          # initialize weights to zero\n",
        "          \n",
        "          data = data.permute(1,2,0,3,4)  #Changing Shape to make it suitable for Resnet Input\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "            # calculate loss\n",
        "          loss = criterion(output, target)\n",
        "          train_loss += loss.item() \n",
        "            # back prop\n",
        "          loss.backward()\n",
        "            \n",
        "            # grad\n",
        "          optimizer.step()\n",
        "            \n",
        "        train_loss /= len(train_loader)\n",
        "            \n",
        "        print('Training loss: %.3f' %(train_loss))\n",
        "        with torch.no_grad():\n",
        "          model.eval()\n",
        "          val_loss = 0\n",
        "          batch_id=0\n",
        "          num_correct = 0\n",
        "          num_samples = 0\n",
        "          for X, X_lens, Y in val_loader:\n",
        "            batch_id+=1\n",
        "            X = X.permute(1,2,0,3,4)\n",
        "            X = X.to(device)\n",
        "            Y = Y.to(device)\n",
        "            out = model(X)\n",
        "            pre, predictions = torch.topk(out,1)\n",
        "            i = 0\n",
        "            for q in predictions:\n",
        "              if Y[i] in predictions[i]:\n",
        "                num_correct += 1\n",
        "              i+=1\n",
        "\n",
        "            num_samples += predictions.size(0)\n",
        "            loss = criterion(out, Y)\n",
        "            val_loss+=loss.item()\n",
        "        val_lpw = val_loss / len(val_loader)\n",
        "        print('Validation Loss: ', val_lpw)\n",
        "        print(\"---------------------------------------------------------------------------\")\n",
        "        print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
        "        print(\"----------------------------------------------------------------------------\")\n",
        "        ape = float(num_correct)/float(num_samples)*100\n",
        "    return train_loss, val_lpw, ape\n",
        "\n",
        "gc.collect()   \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/r3d_18-b3b3357e.pth\" to /root/.cache/torch/hub/checkpoints/r3d_18-b3b3357e.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c666f0440ecf40899a40f28d7d67cf84",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=133546016.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "VideoResNet(\n",
            "  (stem): BasicStem(\n",
            "    (0): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
            "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=400, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI_7RpdFcPq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c16a897d-120c-40cb-e64d-df10ea386bcb"
      },
      "source": [
        "from tqdm import tqdm\n",
        "acc = [] \n",
        "Train_loss = []\n",
        "Test_loss = []\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience, factor=factor, verbose=True)\n",
        "for i in tqdm(range(30)):\n",
        "    train_loss, val_loss, ape = train(1,model,  optimizer, criterion)\n",
        "    scheduler.step(val_loss)\n",
        "    Train_loss.append(train_loss)\n",
        "    Test_loss.append(val_loss)\n",
        "    acc.append(ape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 4.913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  3%|â–Ž         | 1/30 [05:21<2:35:15, 321.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  4.282994316174434\n",
            "---------------------------------------------------------------------------\n",
            "Got 15 / 101 with accuracy 14.85\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 2.847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|â–‹         | 2/30 [10:46<2:30:28, 322.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  3.6634969986402073\n",
            "---------------------------------------------------------------------------\n",
            "Got 28 / 101 with accuracy 27.72\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 1.694\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|â–ˆ         | 3/30 [16:12<2:25:34, 323.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  3.266739171428176\n",
            "---------------------------------------------------------------------------\n",
            "Got 36 / 101 with accuracy 35.64\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 13%|â–ˆâ–Ž        | 4/30 [21:41<2:20:54, 325.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  3.438067527917715\n",
            "---------------------------------------------------------------------------\n",
            "Got 40 / 101 with accuracy 39.60\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|â–ˆâ–‹        | 5/30 [27:06<2:15:29, 325.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  3.6326481699943542\n",
            "---------------------------------------------------------------------------\n",
            "Got 43 / 101 with accuracy 42.57\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|â–ˆâ–ˆ        | 6/30 [32:33<2:10:17, 325.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  3.3130152248419247\n",
            "---------------------------------------------------------------------------\n",
            "Got 36 / 101 with accuracy 35.64\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 23%|â–ˆâ–ˆâ–Ž       | 7/30 [37:57<2:04:36, 325.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  3.4781729716521044\n",
            "---------------------------------------------------------------------------\n",
            "Got 43 / 101 with accuracy 42.57\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 27%|â–ˆâ–ˆâ–‹       | 8/30 [43:24<1:59:22, 325.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  4.125327135507877\n",
            "---------------------------------------------------------------------------\n",
            "Got 40 / 101 with accuracy 39.60\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [48:48<1:53:48, 325.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  3.512879043280219\n",
            "---------------------------------------------------------------------------\n",
            "Got 36 / 101 with accuracy 35.64\n",
            "----------------------------------------------------------------------------\n",
            "Epoch     9: reducing learning rate of group 0 to 3.1600e-05.\n",
            "Training loss: 0.123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [54:14<1:48:28, 325.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.835127715880617\n",
            "---------------------------------------------------------------------------\n",
            "Got 44 / 101 with accuracy 43.56\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [59:41<1:43:12, 325.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  3.0222328075995812\n",
            "---------------------------------------------------------------------------\n",
            "Got 47 / 101 with accuracy 46.53\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.043\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [1:05:06<1:37:44, 325.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.792414853779169\n",
            "---------------------------------------------------------------------------\n",
            "Got 47 / 101 with accuracy 46.53\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.038\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [1:10:33<1:32:25, 326.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.825473044927304\n",
            "---------------------------------------------------------------------------\n",
            "Got 46 / 101 with accuracy 45.54\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.039\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [1:16:00<1:27:02, 326.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.994335488631175\n",
            "---------------------------------------------------------------------------\n",
            "Got 46 / 101 with accuracy 45.54\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [1:21:27<1:21:37, 326.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.754933680479343\n",
            "---------------------------------------------------------------------------\n",
            "Got 48 / 101 with accuracy 47.52\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.034\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [1:26:52<1:16:05, 326.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  3.0772180328002343\n",
            "---------------------------------------------------------------------------\n",
            "Got 48 / 101 with accuracy 47.52\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.034\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [1:32:16<1:10:31, 325.53s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.772214834793256\n",
            "---------------------------------------------------------------------------\n",
            "Got 51 / 101 with accuracy 50.50\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.038\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [1:37:43<1:05:10, 325.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.9489701204001904\n",
            "---------------------------------------------------------------------------\n",
            "Got 49 / 101 with accuracy 48.51\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [1:43:10<59:48, 326.26s/it]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  3.8159331312546363\n",
            "---------------------------------------------------------------------------\n",
            "Got 40 / 101 with accuracy 39.60\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.055\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [1:48:38<54:27, 326.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  3.266842721746518\n",
            "---------------------------------------------------------------------------\n",
            "Got 46 / 101 with accuracy 45.54\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [1:54:05<49:02, 326.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.8758178654198465\n",
            "---------------------------------------------------------------------------\n",
            "Got 46 / 101 with accuracy 45.54\n",
            "----------------------------------------------------------------------------\n",
            "Epoch    21: reducing learning rate of group 0 to 9.9856e-06.\n",
            "Training loss: 0.030\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [1:59:31<43:31, 326.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.650278370970717\n",
            "---------------------------------------------------------------------------\n",
            "Got 50 / 101 with accuracy 49.50\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [2:04:58<38:07, 326.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.7809740408108774\n",
            "---------------------------------------------------------------------------\n",
            "Got 46 / 101 with accuracy 45.54\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [2:10:23<32:37, 326.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.716257269709156\n",
            "---------------------------------------------------------------------------\n",
            "Got 44 / 101 with accuracy 43.56\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [2:15:50<27:11, 326.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.74047227927412\n",
            "---------------------------------------------------------------------------\n",
            "Got 48 / 101 with accuracy 47.52\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [2:21:17<21:46, 326.56s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.6920941449128666\n",
            "---------------------------------------------------------------------------\n",
            "Got 46 / 101 with accuracy 45.54\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [2:26:43<16:18, 326.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  3.475253771130855\n",
            "---------------------------------------------------------------------------\n",
            "Got 48 / 101 with accuracy 47.52\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [2:32:07<10:51, 325.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.648325061568847\n",
            "---------------------------------------------------------------------------\n",
            "Got 47 / 101 with accuracy 46.53\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [2:37:34<05:26, 326.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.7212477830740123\n",
            "---------------------------------------------------------------------------\n",
            "Got 45 / 101 with accuracy 44.55\n",
            "----------------------------------------------------------------------------\n",
            "Training loss: 0.024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [2:42:57<00:00, 325.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss:  2.867851936759857\n",
            "---------------------------------------------------------------------------\n",
            "Got 45 / 101 with accuracy 44.55\n",
            "----------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlPBfLozX6vy"
      },
      "source": [
        "torch.save(model,\"ff2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "t0W41v-3eA3O",
        "outputId": "c06fce68-8156-4396-a372-c75ffa78aa93"
      },
      "source": [
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(Train_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fddc7a6d250>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "T9tuwUDueFWA",
        "outputId": "a68f86c9-364d-44fd-b8aa-3868b45bf1d2"
      },
      "source": [
        "plt.title('Test Loss')\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(Test_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcc9a4f97d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "dG_0dYQ5gta7",
        "outputId": "1927c08c-f196-4e3f-d280-32e659801534"
      },
      "source": [
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Acc')\n",
        "plt.plot(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcc9a462f10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4Ga6JYoLkGU",
        "outputId": "532da1f6-0c6b-4b11-bf87-6d0eb01eb9c0"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import torchvision\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "import gc \n",
        "\n",
        "os.chdir(\"/content/gdrive/MyDrive/FYP\")\n",
        "label_Words = np.load('labels_word.npy',allow_pickle=True)\n",
        "\n",
        "model = torchvision.models.video.r3d_18(pretrained=False)\n",
        "\n",
        "model = torch.load(\"/content/gdrive/MyDrive/FYP/resnetmodel\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "trans = transforms.Compose([transforms.ToTensor(),transforms.Resize((128,128)),\n",
        "                                                 transforms.Normalize(mean=np.array([0.485, 0.456, 0.406]), std=np.array([0.229, 0.224, 0.225]))])\n",
        "\n",
        "def vid_loader(video):\n",
        "        tensorArr=[]\n",
        "        frames = []\n",
        "        imgDir = os.chdir(\"/content/gdrive/MyDrive/FYP/trainData\")\n",
        "        \n",
        "        imgFrames = cv2.VideoCapture(video)\n",
        "        success,image = imgFrames.read()\n",
        "        while success:\n",
        "          frames.append(image)\n",
        "          success,image = imgFrames.read()\n",
        "        for image in frames:\n",
        "            new_image2 = trans(image)\n",
        "            tensorArr.append(new_image2)\n",
        "        \n",
        "        return tensorArr\n",
        "\n",
        "#Image output and labels from loader will be stacked into a tensor\n",
        "video = ['cousin.mp4','hair.mp4','color.mp4','black.mp4']\n",
        "\n",
        "#Function call to loader\n",
        "\n",
        "tensorList= []\n",
        "\n",
        "label = [] #dummy labels\n",
        "\n",
        "for i in video:\n",
        "  tensorArr= vid_loader(i)\n",
        "  stackTensor = torch.stack(tensorArr)\n",
        "  label.append(0)\n",
        "  #Numpy Array of the TensorList\n",
        "  tensorList.append(stackTensor)\n",
        "\n",
        "tensors = []\n",
        "tensors = [t.numpy() for t in tensorList] #changing List into a numpy Array\n",
        "\n",
        "\n",
        "import torch.nn.utils.rnn as rnn\n",
        "#Custom Dataloader\n",
        "class signData(Dataset):\n",
        "    def __init__(self, X, Y, transform = None):\n",
        "        #X is TensorList as argument\n",
        "        self.X = X\n",
        "        #Y is LabelList as argument\n",
        "        self.Y = Y\n",
        "        \n",
        "        if transform == 1:\n",
        "            self.transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                                 transforms.Resize((128,128))\n",
        "                                                 ,transforms.Normalize(mean=np.array([0.485, 0.456, 0.406]), std=np.array([0.229, 0.224, 0.225]))])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        #Accessing every instance of NpTensorArr\n",
        "        imageStack = self.X[index]\n",
        "        #Accesing every instance of NpLabelList\n",
        "        label = self.Y[index]\n",
        "        return torch.from_numpy(imageStack), len(imageStack), label \n",
        "\n",
        "#Use my_collate for Image Batching and normalizing image sizes\n",
        "def my_collate(batch):\n",
        "    inputs = rnn.pad_sequence([s[0] for s in batch], padding_value=0.0)\n",
        "    input_sizes = torch.LongTensor([s[1] for s in batch])\n",
        "    target = torch.LongTensor([s[2] for s in batch])\n",
        "\n",
        "    return inputs, input_sizes, target    \n",
        "\n",
        "\n",
        "\n",
        "#Transform Images\n",
        "trans = transforms.Compose([transforms.ToTensor(),transforms.Resize((128,128)),\n",
        "                                                 transforms.Normalize(mean=np.array([0.485, 0.456, 0.406]), std=np.array([0.229, 0.224, 0.225]))])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x = signData(tensors,label)\n",
        "\n",
        "    #Numpy Array of the TensorList\n",
        "train_arg = dict(batch_size=len(x), shuffle=False, collate_fn = my_collate)\n",
        "val_loader = DataLoader(x, **train_arg)\n",
        "cnn_results= ''\n",
        "model.eval()\n",
        "for X, X_lens, Y in val_loader:\n",
        "  X = X.permute(1,2,0,3,4)\n",
        "  X = X.to(device)\n",
        "  Y = Y.to(device)\n",
        "\n",
        "  out = model(X)\n",
        "\n",
        "  pre, predictions = torch.topk(out,1)\n",
        "  for i in predictions:\n",
        "    for x in i:\n",
        "      cnn_results = cnn_results + label_Words[x]+' '\n",
        "cnn_results = cnn_results[0:(len(cnn_results)-1)]\n",
        "print(cnn_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cousin hair color black\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74c35FjDDmke"
      },
      "source": [
        "## Module 2 of \"Sign Language With Deep Learning\"\n",
        "## Seq2Seq Nueral Network\n",
        "#### This module will convert the CNN output of English Keywords from Module 1 into English Language Sentences with proper use of grammar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJPsqkeYDmkf"
      },
      "source": [
        "## Libraries & Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2NKRNPiy8yG"
      },
      "source": [
        "import string\n",
        "import re\n",
        "from pickle import dump\n",
        "from unicodedata import normalize\n",
        "from numpy import array\n",
        "from google.colab import drive\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqg_5i3yDmkg"
      },
      "source": [
        "#### Google Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWzVP35VzLoM",
        "outputId": "4421b431-7fb1-45b0-bda4-3c5914a0ddff"
      },
      "source": [
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "os.chdir(\"/content/gdrive/MyDrive/FYP\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHgmUNX_Dmkh"
      },
      "source": [
        "### Data Cleaning & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_KSB5qwy-sm",
        "outputId": "75041244-ca81-45ab-e11f-b24748d1292c"
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "    # open the file as read only\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\n",
        "    # read all text\n",
        "    text = file.read()\n",
        "    # close the file\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "# split a loaded document into pairs\n",
        "def to_pairs(doc):\n",
        "    lines = doc.strip().split('\\n')\n",
        "    pairs = [line.split('\\t') for line in  lines]\n",
        "    return pairs\n",
        "\n",
        "# clean a list of lines\n",
        "def clean_pairs(lines):\n",
        "    lc = lines\n",
        "    #print(lc[:1],\" lc\")\n",
        "    cleaned = list()\n",
        "    # prepare regex for char filtering\n",
        "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "    # prepare translation table for removing punctuation\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    for pair in lines:\n",
        "        #print(pair)\n",
        "        clean_pair = list()\n",
        "        for line in pair:\n",
        "            #print(line, \"oldline\")\n",
        "            # normalize unicode characters\n",
        "            line = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "            line = line.decode('UTF-8')\n",
        "            # tokenize on white space\n",
        "            line = line.split()\n",
        "            # convert to lowercase\n",
        "            line = [word.lower() for word in line]\n",
        "            # remove punctuation from each token\n",
        "            line = [word.translate(table) for word in line]\n",
        "            # remove non-printable chars form each token\n",
        "            line = [re_print.sub('', w) for w in line]\n",
        "      \n",
        "      # remove tokens with numbers in them\n",
        "            line = [word for word in line if word.isalpha()]\n",
        "            #print(line,\" up line\")\n",
        "            # store as string\n",
        "            clean_pair.append(' '.join(line))\n",
        "        cleaned.append(clean_pair)\n",
        "    return array(cleaned)\n",
        "\n",
        "# save a list of clean sentences to file\n",
        "def save_clean_data(sentences, filename):\n",
        "    dump(sentences, open(filename, 'wb'))\n",
        "    print('Saved: %s' % filename)\n",
        "\n",
        "\n",
        "\n",
        "def load_dataset(filename, arrSize, newFileName):\n",
        "    # load dataset\n",
        "    #filename = 'Input-OutputFinal.txt'\n",
        "    doc = load_doc(filename)\n",
        "    # split into sentence-word pairs\n",
        "    pairs = to_pairs(doc)\n",
        "    #print(pairs)\n",
        "    # clean sentences\n",
        "    clean_pairsS = clean_pairs(pairs)\n",
        "    # save clean pairs to file\n",
        "    save_clean_data(clean_pairsS, newFileName)\n",
        "    # spot check\n",
        "    \n",
        "    if filename == \"Dataset/Input-OutputFinal.txt\":\n",
        "      for i in range(arrSize):\n",
        "              print('[%s] <= [%s]' % (clean_pairsS[i,0], clean_pairsS[i,1])) \n",
        "    else:\n",
        "      for i in range(arrSize):\n",
        "              print('[%s]' % (clean_pairsS[i,1]))\n",
        "    \n",
        "\n",
        "\n",
        "load_dataset(\"Input-OutputFinal.txt\", 10, 'words-sents.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: words-sents.pkl\n",
            "[go]\n",
            "[go]\n",
            "[go]\n",
            "[go]\n",
            "[hi]\n",
            "[run]\n",
            "[run]\n",
            "[who]\n",
            "[fire]\n",
            "[fire]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArelrUnADmki"
      },
      "source": [
        "### Preprocessed Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu8-94R6yxbP",
        "outputId": "fb67e6cb-e9e5-4e82-afab-60eaa83577c0"
      },
      "source": [
        "from pickle import dump\n",
        "from pickle import load\n",
        "from numpy.random import rand\n",
        "from numpy.random import shuffle\n",
        "#import load\n",
        " \n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "    return load(open(filename, 'rb'))\n",
        " \n",
        "# save a list of clean sentences to file\n",
        "def save_clean_data(sentences, filename):\n",
        "    dump(sentences, open(filename, 'wb'))\n",
        "    print('Saved: %s' % filename)\n",
        " \n",
        "# load dataset\n",
        "raw_dataset = load_clean_sentences('words-sents.pkl')\n",
        " \n",
        "# reduce dataset size\n",
        "n_sentences = 25000\n",
        "dataset = raw_dataset[:n_sentences, :]\n",
        "# random shuffle\n",
        "shuffle(dataset)\n",
        "# split into train/test\n",
        "train, test = dataset[:23000], dataset[23000:]\n",
        "print(len(train))\n",
        "print(len(test))\n",
        "# save\n",
        "save_clean_data(dataset, 'words-sents-both.pkl')\n",
        "save_clean_data(train, 'words-sents-train.pkl')\n",
        "save_clean_data(test, 'words-sents-test.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23000\n",
            "2000\n",
            "Saved: words-sents-both.pkl\n",
            "Saved: words-sents-train.pkl\n",
            "Saved: words-sents-test.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9KlTvg-Dmkj"
      },
      "source": [
        "### Seq2Seq Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHpZ_UJD2i6o",
        "outputId": "916b881e-7ab0-491b-87d1-d7cfedb63df1"
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        " \n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "    return load(open(filename, 'rb'))\n",
        " \n",
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer\n",
        " \n",
        "# max sentence length\n",
        "def max_length(lines):\n",
        "    return max(len(line.split()) for line in lines)\n",
        " \n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "    # integer encode sequences\n",
        "    X = tokenizer.texts_to_sequences(lines)\n",
        "    # pad sequences with 0 values\n",
        "    X = pad_sequences(X, maxlen=length, padding='post')\n",
        "    return X\n",
        " \n",
        "# one hot encode target sequence\n",
        "def encode_output(sequences, vocab_size):\n",
        "    ylist = list()\n",
        "    for sequence in sequences:\n",
        "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
        "        ylist.append(encoded)\n",
        "    y = array(ylist)\n",
        "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
        "    return y\n",
        " \n",
        "# define NMT model\n",
        "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
        "  model.add(LSTM(n_units))\n",
        "  #model.add(Dropout(0.5))\n",
        "  model.add(RepeatVector(tar_timesteps))\n",
        "  model.add(LSTM(n_units, return_sequences=True))\n",
        "  #model.add(Dropout(0.5))\n",
        "  model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
        "  return model\n",
        " \n",
        "# load datasets\n",
        "dataset = load_clean_sentences('words-sents-both.pkl')\n",
        "train = load_clean_sentences('words-sents-train.pkl')\n",
        "test = load_clean_sentences('words-sents-test.pkl')\n",
        " \n",
        "# prepare words tokenizer\n",
        "word_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "word_vocab_size = len(word_tokenizer.word_index) + 1\n",
        "word_length = max_length(dataset[:, 0])\n",
        "print('Words Vocabulary Size: %d' % word_vocab_size)\n",
        "print('Words Max Length: %d' % (word_length))\n",
        "# prepare sentences tokenizer\n",
        "sent_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "sent_vocab_size = len(sent_tokenizer.word_index) + 1\n",
        "sent_length = max_length(dataset[:, 1])\n",
        "print('Sentences Vocabulary Size: %d' % sent_vocab_size)\n",
        "print('Sentences Max Length: %d' % (sent_length))\n",
        " \n",
        "# prepare training data\n",
        "trainX = encode_sequences(sent_tokenizer, word_length, train[:, 1])\n",
        "trainY = encode_sequences(word_tokenizer, word_length, train[:, 0])\n",
        "trainY = encode_output(trainY, word_vocab_size)\n",
        "# prepare validation data\n",
        "testX = encode_sequences(sent_tokenizer, sent_length, test[:, 1])\n",
        "testY = encode_sequences(word_tokenizer, word_length, test[:, 0])\n",
        "testY = encode_output(testY, word_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words Vocabulary Size: 4403\n",
            "Words Max Length: 7\n",
            "Sentences Vocabulary Size: 4382\n",
            "Sentences Max Length: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "IwbUuhk7Dmkk",
        "outputId": "d70fe70b-22fd-4d9d-f801-4a5adf34d06c"
      },
      "source": [
        "# define model\n",
        "model = define_model(sent_vocab_size, word_vocab_size, sent_length, word_length, 256)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "# summarize defined model\n",
        "print(model.summary())\n",
        "plot_model(model, to_file='model.png', show_shapes=True)\n",
        "# fit model\n",
        "filename = 'model.h5'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "history = model.fit(trainX, trainY, epochs=30, batch_size=64, validation_data=(testX, testY), callbacks=[checkpoint], verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 5, 256)            1121792   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 7, 256)            525312    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 7, 4403)           1131571   \n",
            "=================================================================\n",
            "Total params: 3,303,987\n",
            "Trainable params: 3,303,987\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 5) for input KerasTensor(type_spec=TensorSpec(shape=(None, 5), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 7).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-6ef570d73dbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    980\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m                 ))\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m       \u001b[0m_attach_error_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_per_replica\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_scalar_summaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    430\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0mprogram_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProgramContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m     \u001b[0mconverted_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_actual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_entity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogram_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m       \u001b[0m_log_callargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_convert_actual\u001b[0;34m(entity, program_ctx)\u001b[0m\n\u001b[1;32m    272\u001b[0m                      ' try passing f.python_function instead.')\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m   \u001b[0mtransformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TRANSPILER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogram_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_module'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/transpiler.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, obj, user_context)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \"\"\"\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Non-function: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/transpiler.py\u001b[0m in \u001b[0;36mtransform_function\u001b[0;34m(self, fn, user_context)\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%s is not cached for subkey %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_subkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m           \u001b[0;31m# TODO(mdan): Confusing overloading pattern. Fix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m           \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPyToPy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/transpiler.py\u001b[0m in \u001b[0;36mtransform_function\u001b[0;34m(self, fn, user_context)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_erase_arg_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_ast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mtransform_ast\u001b[0;34m(self, node, ctx)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;31m# canonicalization creates.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontinue_statements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_statements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLISTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m       \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/converters/return_statements.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(node, ctx, default_to_null_return)\u001b[0m\n\u001b[1;32m    393\u001b[0m   \u001b[0;34m\"\"\"Ensure a function has only a single return, at the end.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqual_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m   \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m   \u001b[0;31m# Note: Technically, these two could be merged into a single walk, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(node, context, parent_scope)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mActivityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/transformer.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mentry_expr_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0;31m# Adjust for consistency: replacing the value of an Expr with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ast.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'visit_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_visit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgeneric_visit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\u001b[0m in \u001b[0;36mvisit_FunctionDef\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    599\u001b[0m       \u001b[0;31m# be strictly needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enter_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m       \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exit_and_record_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNodeAnno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBODY_SCOPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/transformer.py\u001b[0m in \u001b[0;36mvisit_block\u001b[0;34m(self, nodes, before_visit, after_visit)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mbefore_visit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m       \u001b[0mreplacement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mafter_visit\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreplacement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/transformer.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mentry_expr_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0;31m# Adjust for consistency: replacing the value of an Expr with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ast.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'visit_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_visit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgeneric_visit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\u001b[0m in \u001b[0;36mvisit_With\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    649\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mvisit_With\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enter_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m     \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_visit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exit_and_record_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNodeAnno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBODY_SCOPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ast.py\u001b[0m in \u001b[0;36mgeneric_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/transformer.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mentry_expr_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0;31m# Adjust for consistency: replacing the value of an Expr with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ast.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'visit_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_visit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgeneric_visit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\u001b[0m in \u001b[0;36mvisit_For\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enter_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasanno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXTRA_LOOP_TEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetanno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXTRA_LOOP_TEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/transformer.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mentry_expr_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0;31m# Adjust for consistency: replacing the value of an Expr with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ast.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'visit_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_visit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgeneric_visit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ast.py\u001b[0m in \u001b[0;36mgeneric_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/transformer.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    434\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m     \u001b[0mparent_origin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_origin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasanno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mORIGIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_origin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetanno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mORIGIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8gcjk1FDmkl"
      },
      "source": [
        "### Model Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "vmFXovdU6MmB",
        "outputId": "c30c572b-a911-4009-ac03-02fcd6b2a479"
      },
      "source": [
        "# list all data in history\n",
        "epochList = list(range(0,31))\n",
        "#print(epochList)\n",
        "print(history.history.keys())\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Training Loss', 'Validation Loss'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'val_loss'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c03eDfKDmkl"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHtyDphzDqrD",
        "scrolled": true
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        " \n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "    return load(open(filename, 'rb'))\n",
        " \n",
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer\n",
        " \n",
        "# max sentence length\n",
        "def max_length(lines):\n",
        "    return max(len(line.split()) for line in lines)\n",
        " \n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "    # integer encode sequences\n",
        "    X = tokenizer.texts_to_sequences(lines)\n",
        "    # pad sequences with 0 values\n",
        "    X = pad_sequences(X, maxlen=length, padding='post')\n",
        "    return X\n",
        " \n",
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        " \n",
        "# generate target given source sequence\n",
        "def predict_sequence(model, tokenizer, source):\n",
        "    prediction = model.predict(source, verbose=0)[0]\n",
        "    integers = [argmax(vector) for vector in prediction]\n",
        "    target = list()\n",
        "    for i in integers:\n",
        "        word = word_for_id(i, tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "        target.append(word)\n",
        "    return ' '.join(target)\n",
        " \n",
        "# evaluate the skill of the model\n",
        "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
        "    actual, predicted = list(), list()\n",
        "    for i, source in enumerate(sources):\n",
        "        # translate encoded source text\n",
        "        source = source.reshape((1, source.shape[0]))\n",
        "        translation = predict_sequence(model, word_tokenizer, source)\n",
        "        raw_target, raw_src = raw_dataset[i]\n",
        "        if i < 10:\n",
        "            print('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
        "        actual.append([raw_target.split()])\n",
        "        predicted.append(translation.split())\n",
        "    # calculate BLEU score\n",
        "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6q-DKncpHpS"
      },
      "source": [
        "def evaluate_modelCNN(model, tokenizer, sources, raw_dataset):\n",
        "    actual, predicted = list(), list()\n",
        "    for i, source in enumerate(sources):\n",
        "        # translate encoded source text\n",
        "        source = source.reshape((1, source.shape[0]))\n",
        "        translation = predict_sequence(model, word_tokenizer, source)\n",
        "        raw_target, raw_src = raw_dataset[i]\n",
        "        if i < 10:\n",
        "            print('src=[%s], predicted=[%s]' % (raw_src, translation))\n",
        "        actual.append([raw_target.split()])\n",
        "        predicted.append(translation.split())\n",
        "\n",
        "def evalCNN(filename):\n",
        "  dataset = load_clean_sentences('words-sents-both.pkl')\n",
        "  # prepare word tokenizer\n",
        "  word_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "  word_vocab_size = len(word_tokenizer.word_index) + 1\n",
        "  word_length = max_length(dataset[:, 0])\n",
        "  # prepare sentences tokenizer\n",
        "  sent_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "  sent_vocab_size = len(sent_tokenizer.word_index) + 1\n",
        "  sent_length = max_length(dataset[:, 1])\n",
        "  # prepare data\n",
        "  testX = encode_sequences(sent_tokenizer, sent_length, filename[:, 1])\n",
        "  \n",
        "  # load model\n",
        "  print(os.getcwd)\n",
        "  #model = load_model('model.h5')\n",
        "  # test on some testCNN sequences\n",
        "  print('Custom/CNN Prediction:\\n')\n",
        "  evaluate_modelCNN(model, word_tokenizer, testX, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9bGGM2bVmI3",
        "outputId": "0187d55f-baf7-4f1b-86cc-4c982f73cc0d"
      },
      "source": [
        "# load datasets\n",
        "dataset = load_clean_sentences('words-sents-both.pkl')\n",
        "train = load_clean_sentences('words-sents-train.pkl')\n",
        "test = load_clean_sentences('words-sents-test.pkl')\n",
        "# prepare word tokenizer\n",
        "word_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "word_vocab_size = len(word_tokenizer.word_index) + 1\n",
        "word_length = max_length(dataset[:, 0])\n",
        "# prepare sentences tokenizer\n",
        "sent_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "sent_vocab_size = len(sent_tokenizer.word_index) + 1\n",
        "sent_length = max_length(dataset[:, 1])\n",
        "# prepare data\n",
        "trainX = encode_sequences(sent_tokenizer, sent_length, train[:, 1])\n",
        "testX = encode_sequences(sent_tokenizer, sent_length, test[:, 1])\n",
        " \n",
        "# load model\n",
        "#model = load_model('model.h5')\n",
        "# test on some training sequences\n",
        "print('Train Set Results')\n",
        "evaluate_model(model, word_tokenizer, trainX, train)\n",
        "# test on some test sequences\n",
        "print('\\n')\n",
        "print('Test Set Results')\n",
        "evaluate_modelCNN(model, word_tokenizer, testX, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Results\n",
            "\n",
            "\n",
            "Test Set Results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5-F6rGJPqKr"
      },
      "source": [
        "**Custom CNN Predictions**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLfcJKTh13Gq"
      },
      "source": [
        "def customInput(custIn):\n",
        "  clean_pairsCNN = clean_pairs(custIn)\n",
        "  save_clean_data(clean_pairsCNN, 'customInput.pkl')\n",
        "  testCNN = load_clean_sentences('customInput.pkl')\n",
        "  evalCNN(testCNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_kSsBQIMke_",
        "outputId": "df7a31ac-d7c9-41e2-9e9e-6a0c6889a9a9"
      },
      "source": [
        "customInput([['h', 'cat color black']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: customInput.pkl\n",
            "<built-in function getcwd>\n",
            "Custom/CNN Prediction:\n",
            "\n",
            "src=[cat color black], predicted=[well prepared used]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUCEzPDQMif5",
        "outputId": "afce38ac-b0ce-46d2-a6e9-22257884b67a"
      },
      "source": [
        "customInput([['h', 'cousin hair color black']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: customInput.pkl\n",
            "<built-in function getcwd>\n",
            "Custom/CNN Prediction:\n",
            "\n",
            "src=[cousin hair color black], predicted=[hammer told still tight]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzjRz-v2m-Gr",
        "outputId": "5bfae59d-0702-49c4-ddaa-4d94612aa59e"
      },
      "source": [
        "customInput([['h', cnn_results]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: customInput.pkl\n",
            "<built-in function getcwd>\n",
            "Custom/CNN Prediction:\n",
            "\n",
            "src=[cousin hair color black], predicted=[hammer told still tight]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}